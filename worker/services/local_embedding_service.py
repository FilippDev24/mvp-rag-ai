import os
import time
import logging
from typing import List, Dict, Any
import requests
import json

logger = logging.getLogger(__name__)

class LocalEmbeddingService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π FastAPI —Å–µ—Ä–≤–µ—Ä
    –û–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ –Ω–∞—Ç–∏–≤–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É –Ω–∞ —Ö–æ—Å—Ç–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    
    –ü–û–†–¢: 8003 (–ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
    """
    
    def __init__(self):
        # URL –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ (host.docker.internal –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ö–æ—Å—Ç—É –∏–∑ Docker)
        self.base_url = os.getenv('LOCAL_EMBEDDING_URL', 'http://host.docker.internal:8003')
        self.timeout = 30  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
        self.logger = logger
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ (–∫—ç—à–∏—Ä—É–µ—Ç—Å—è)
        self._model_info = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self._check_server_health()
    
    def _check_server_health(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            response = requests.get(
                f"{self.base_url}/health",
                timeout=5
            )
            if response.status_code == 200:
                health_data = response.json()
                self.logger.info(f"üöÄ Local embedding server is healthy: device={health_data.get('device', 'unknown')}, port={health_data.get('port', 8003)}")
                return True
            else:
                self.logger.warning(f"‚ö†Ô∏è  Local embedding server returned status {response.status_code}")
                return False
                
        except requests.exceptions.RequestException as e:
            self.logger.error(f"‚ùå Cannot connect to local embedding server: {str(e)}")
            self.logger.error("üîß Make sure to start the local server with: python local_embedding_server.py")
            return False
    
    def _get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
        if self._model_info is None:
            try:
                response = requests.get(f"{self.base_url}/model-info", timeout=5)
                if response.status_code == 200:
                    self._model_info = response.json()
                    self.logger.info(f"Model info cached: {self._model_info.get('model_name', 'unknown')}")
                else:
                    self.logger.error(f"Failed to get model info: {response.status_code}")
                    # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
                    self._model_info = {
                        "model_name": "intfloat/multilingual-e5-large-instruct",
                        "dimension": 1024,
                        "max_seq_length": 512
                    }
            except Exception as e:
                self.logger.error(f"Error getting model info: {str(e)}")
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
                self._model_info = {
                    "model_name": "intfloat/multilingual-e5-large-instruct",
                    "dimension": 1024,
                    "max_seq_length": 512
                }
        
        return self._model_info
    
    def generate_query_embedding(self, query: str) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            start_time = time.time()
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            request_data = {
                "text": query,
                "is_query": True
            }
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É
            response = requests.post(
                f"{self.base_url}/embed",
                json=request_data,
                timeout=self.timeout,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code != 200:
                raise Exception(f"Server returned status {response.status_code}: {response.text}")
            
            result_data = response.json()
            total_time = (time.time() - start_time) * 1000
            
            self.logger.info(
                f"‚ö° Generated query embedding in {total_time:.1f}ms "
                f"(server processing: {result_data.get('processing_time_ms', 0):.1f}ms, "
                f"device: {result_data.get('device_used', 'unknown')})"
            )
            
            return {
                "embedding": result_data["embedding"],
                "metrics": {
                    "embedding_time_ms": result_data["processing_time_ms"],
                    "total_time_ms": total_time,
                    "tokens_in": result_data["tokens"],
                    "model": self._get_model_info().get("model_name", "unknown"),
                    "dimension": self._get_model_info().get("dimension", 1024),
                    "device_used": result_data["device_used"],
                    "detected_language": result_data.get("detected_language"),
                    "instruction_prefix": result_data.get("instruction_prefix"),
                    "instruct_format": True,
                    "service": "local_embedding_server"
                }
            }
            
        except requests.exceptions.Timeout:
            self.logger.error(f"‚è∞ Timeout waiting for embedding server (>{self.timeout}s)")
            raise Exception("Embedding server timeout")
            
        except requests.exceptions.ConnectionError:
            self.logger.error("‚ùå Cannot connect to local embedding server")
            self.logger.error("üîß Make sure to start: python local_embedding_server.py")
            raise Exception("Cannot connect to embedding server")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error calling local embedding server: {str(e)}")
            raise e
    
    def generate_batch_embeddings(self, texts: List[str], is_query: bool = False) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            is_query: True –µ—Å–ª–∏ —ç—Ç–æ –∑–∞–ø—Ä–æ—Å—ã, False –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            if not texts:
                return {
                    "embeddings": [],
                    "metrics": {
                        "embedding_time_ms": 0,
                        "total_time_ms": 0,
                        "total_tokens": 0,
                        "batch_size": 0,
                        "service": "local_embedding_server"
                    }
                }
            
            start_time = time.time()
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            request_data = {
                "texts": texts,
                "is_query": is_query,
                "batch_size": min(len(texts), 32)  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            }
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É
            response = requests.post(
                f"{self.base_url}/embed-batch",
                json=request_data,
                timeout=self.timeout,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code != 200:
                raise Exception(f"Server returned status {response.status_code}: {response.text}")
            
            result_data = response.json()
            total_time = (time.time() - start_time) * 1000
            
            self.logger.info(
                f"‚ö° Generated {len(result_data['embeddings'])} batch embeddings in {total_time:.1f}ms "
                f"(server processing: {result_data.get('processing_time_ms', 0):.1f}ms, "
                f"device: {result_data.get('device_used', 'unknown')})"
            )
            
            return {
                "embeddings": result_data["embeddings"],
                "metrics": {
                    "embedding_time_ms": result_data["processing_time_ms"],
                    "total_time_ms": total_time,
                    "total_tokens": result_data["total_tokens"],
                    "batch_size": len(texts),
                    "model": result_data["model_info"].get("model", "unknown"),
                    "device_used": result_data["device_used"],
                    "is_query": is_query,
                    "instruct_format": is_query,
                    "service": "local_embedding_server"
                }
            }
            
        except requests.exceptions.Timeout:
            self.logger.error(f"‚è∞ Timeout waiting for embedding server (>{self.timeout}s)")
            raise Exception("Embedding server timeout")
            
        except requests.exceptions.ConnectionError:
            self.logger.error("‚ùå Cannot connect to local embedding server")
            self.logger.error("üîß Make sure to start: python local_embedding_server.py")
            raise Exception("Cannot connect to embedding server")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error calling local embedding server: {str(e)}")
            raise e
    
    def get_embedding_dimension(self) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        return self._get_model_info().get("dimension", 1024)
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
        model_info = self._get_model_info()
        return {
            "model_name": model_info.get("model_name", "intfloat/multilingual-e5-large-instruct"),
            "dimension": model_info.get("dimension", 1024),
            "max_seq_length": model_info.get("max_seq_length", 512),
            "batch_size": 32,
            "service": "local_embedding_server",
            "device": model_info.get("device", "unknown"),
            "port": model_info.get("port", 8003)
        }
    
    def test_performance(self, num_texts: int = 10) -> Dict[str, Any]:
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        test_texts = [f"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–º–µ—Ä {i} –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤" for i in range(num_texts)]
        
        start_time = time.time()
        result = self.generate_batch_embeddings(test_texts, is_query=False)
        total_time = time.time() - start_time
        
        return {
            "num_texts": num_texts,
            "total_time_ms": total_time * 1000,
            "time_per_text_ms": (total_time * 1000) / num_texts,
            "embeddings_count": len(result["embeddings"]),
            "server_available": len(result["embeddings"]) > 0,
            "server_processing_time_ms": result["metrics"].get("embedding_time_ms", 0)
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
_global_local_embedding_service = None

def get_local_embedding_service() -> LocalEmbeddingService:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä LocalEmbeddingService"""
    global _global_local_embedding_service
    
    if _global_local_embedding_service is None:
        _global_local_embedding_service = LocalEmbeddingService()
    
    return _global_local_embedding_service
