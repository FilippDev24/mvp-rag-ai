#!/usr/bin/env python3
"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
–ü–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –Ω–∞–π—Ç–∏ –ø—Ä–∏—á–∏–Ω—ã –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import os
import sys
import json
import time
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ worker –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.database_service import DatabaseService
from services.embedding_service import EmbeddingService
from services.search_service import get_search_service
from services.local_reranking_service import LocalRerankingService
from services.reranking_service import RerankingService

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class DiagnosticResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    query: str
    access_level: int
    vector_results: List[Dict]
    bm25_results: List[Dict]
    fused_results: List[Dict]
    reranked_results: List[Dict]
    rerank_scores: List[float]
    thresholds: Dict[str, float]
    diagnostics: Dict[str, Any]

class SearchDiagnostics:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        self.database_service = None
        self.embedding_service = None
        self.search_service = None
        self.reranking_service = None
        self._initialize_services()
    
    def _initialize_services(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤...")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤ (–∫–∞–∫ –≤ tasks.py)
            self.database_service = DatabaseService()
            self.embedding_service = EmbeddingService()
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–ª–∏ –æ–±—ã—á–Ω—ã–π —Ä–µ—Ä–∞–Ω–∂–µ—Ä
            try:
                self.reranking_service = LocalRerankingService()
                logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º LocalRerankingService")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  LocalRerankingService –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                self.reranking_service = RerankingService()
                logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º RerankingService")
            
            self.search_service = get_search_service(
                self.database_service,
                self.embedding_service, 
                self.reranking_service
            )
            
            logger.info("‚úÖ –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
            raise
    
    def diagnose_query(
        self, 
        query: str, 
        access_level: int = 100,
        top_k: int = 30,
        rerank_top_k: int = 10
    ) -> DiagnosticResult:
        """
        –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            access_level: –£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞
            rerank_top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        """
        logger.info(f"üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º BM25 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self.search_service._ensure_bm25_initialized(access_level)
        
        # 1. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        logger.info("üìä –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫...")
        vector_results, embedding_metrics = self.search_service._vector_search(query, access_level, top_k)
        
        # 2. BM25 –ø–æ–∏—Å–∫
        logger.info("üìù –í—ã–ø–æ–ª–Ω—è–µ–º BM25 –ø–æ–∏—Å–∫...")
        bm25_results = self.search_service._bm25_search(query, access_level, top_k)
        
        # 3. RRF Fusion
        logger.info("üîÄ –í—ã–ø–æ–ª–Ω—è–µ–º RRF fusion...")
        fused_results = self.search_service._rrf_fusion(vector_results, bm25_results)
        
        # 4. –†–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
        logger.info("üéØ –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        reranked_results, rerank_diagnostics = self._detailed_rerank(query, fused_results, rerank_top_k)
        
        # 5. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        diagnostics = self._analyze_results(
            query, vector_results, bm25_results, fused_results, 
            reranked_results, rerank_diagnostics
        )
        
        return DiagnosticResult(
            query=query,
            access_level=access_level,
            vector_results=vector_results,
            bm25_results=bm25_results,
            fused_results=fused_results,
            reranked_results=reranked_results,
            rerank_scores=rerank_diagnostics.get('scores', []),
            thresholds=rerank_diagnostics.get('thresholds', {}),
            diagnostics=diagnostics
        )
    
    def _detailed_rerank(self, query: str, results: List[Dict], top_k: int) -> tuple:
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
        if not results:
            return [], {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents = [result["content"] for result in results]
        
        # –†–µ—Ä–∞–Ω–∂–∏—Ä—É–µ–º
        reranked = self.reranking_service.rerank_results(query, documents, top_k)
        
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        all_reranked_results = []
        scores = []
        
        for rerank_result in reranked:
            original_index = rerank_result["index"]
            if original_index < len(results):
                result = results[original_index].copy()
                result.update({
                    "rerank_score": rerank_result["score"],
                    "raw_logit": rerank_result.get("raw_logit", 0),
                    "final_rank": len(all_reranked_results) + 1
                })
                all_reranked_results.append(result)
                scores.append(rerank_result["score"])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏ (–∫–æ–ø–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –∏–∑ search_service)
        if scores:
            best_score = max(scores)
            worst_score = min(scores)
            score_range = best_score - worst_score
            
            if score_range > 2.0:
                high_threshold = best_score * 0.8
                general_threshold = best_score * 0.4
            elif score_range > 1.0:
                high_threshold = best_score * 0.7
                general_threshold = best_score * 0.3
            else:
                high_threshold = best_score - 0.1
                general_threshold = best_score * 0.5
        else:
            high_threshold = 0
            general_threshold = 0
            best_score = 0
            worst_score = 0
            score_range = 0
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥–∞–º
        filtered_results = [r for r in all_reranked_results if r["rerank_score"] >= high_threshold]
        
        diagnostics = {
            'scores': scores,
            'best_score': best_score,
            'worst_score': worst_score,
            'score_range': score_range,
            'thresholds': {
                'high_relevance': high_threshold,
                'general_chat': general_threshold
            },
            'total_results': len(all_reranked_results),
            'filtered_results': len(filtered_results),
            'filtered_out': len(all_reranked_results) - len(filtered_results)
        }
        
        return filtered_results, diagnostics
    
    def _analyze_results(
        self, 
        query: str, 
        vector_results: List[Dict], 
        bm25_results: List[Dict],
        fused_results: List[Dict], 
        reranked_results: List[Dict],
        rerank_diagnostics: Dict
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
        vector_ids = {r['id'] for r in vector_results}
        bm25_ids = {r['id'] for r in bm25_results}
        intersection = vector_ids & bm25_ids
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        quality_analysis = self._analyze_quality(query, reranked_results)
        
        return {
            'query_analysis': {
                'length': len(query),
                'words': len(query.split()),
                'has_numbers': any(c.isdigit() for c in query),
                'has_dates': self._has_dates(query),
                'language': 'ru' if any(ord(c) > 127 for c in query) else 'en'
            },
            'search_results': {
                'vector_count': len(vector_results),
                'bm25_count': len(bm25_results),
                'intersection_count': len(intersection),
                'intersection_ratio': len(intersection) / max(len(vector_ids), 1),
                'fused_count': len(fused_results),
                'final_count': len(reranked_results)
            },
            'reranking': rerank_diagnostics,
            'quality': quality_analysis,
            'recommendations': self._generate_recommendations(
                query, vector_results, bm25_results, reranked_results, rerank_diagnostics
            )
        }
    
    def _analyze_quality(self, query: str, results: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not results:
            return {'status': 'no_results', 'issues': ['–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤']}
        
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ—Ä—ã —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        scores = [r.get('rerank_score', 0) for r in results]
        if scores:
            avg_score = sum(scores) / len(scores)
            min_score = min(scores)
            max_score = max(scores)
            
            if max_score < 3.0:
                issues.append(f'–ù–∏–∑–∫–∏–µ —Å–∫–æ—Ä—ã —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è (–º–∞–∫—Å: {max_score:.2f})')
            
            if avg_score < 2.0:
                issues.append(f'–ù–∏–∑–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä ({avg_score:.2f})')
            
            if max_score - min_score < 0.5:
                issues.append('–ú–∞–ª—ã–π —Ä–∞–∑–±—Ä–æ—Å —Å–∫–æ—Ä–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ –ø–ª–æ—Ö–æ–µ —Ä–∞–∑–ª–∏—á–µ–Ω–∏–µ')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        query_words = set(query.lower().split())
        for i, result in enumerate(results[:3]):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ø-3
            content = result.get('content', '').lower()
            content_words = set(content.split())
            
            overlap = len(query_words & content_words)
            if overlap == 0:
                issues.append(f'–†–µ–∑—É–ª—å—Ç–∞—Ç #{i+1} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞')
        
        status = 'good' if not issues else 'issues_found'
        
        return {
            'status': status,
            'issues': issues,
            'scores_stats': {
                'min': min(scores) if scores else 0,
                'max': max(scores) if scores else 0,
                'avg': sum(scores) / len(scores) if scores else 0,
                'count': len(scores)
            }
        }
    
    def _has_dates(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞—Ç –≤ —Ç–µ–∫—Å—Ç–µ"""
        import re
        date_patterns = [
            r'\d{2}\.\d{2}\.\d{4}',  # DD.MM.YYYY
            r'\d{4}-\d{2}-\d{2}',   # YYYY-MM-DD
            r'\d{1,2}\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+\d{4}'
        ]
        return any(re.search(pattern, text, re.IGNORECASE) for pattern in date_patterns)
    
    def _generate_recommendations(
        self, 
        query: str, 
        vector_results: List[Dict], 
        bm25_results: List[Dict],
        reranked_results: List[Dict], 
        rerank_diagnostics: Dict
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤
        thresholds = rerank_diagnostics.get('thresholds', {})
        best_score = rerank_diagnostics.get('best_score', 0)
        
        if best_score < 2.0:
            recommendations.append('üî¥ –ö–†–ò–¢–ò–ß–ù–û: –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–µ —Å–∫–æ—Ä—ã —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è - –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–ø—Ä–æ—Å –Ω–µ —Å–≤—è–∑–∞–Ω —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏')
        elif best_score < 4.0:
            recommendations.append('üü° –í–ù–ò–ú–ê–ù–ò–ï: –ù–∏–∑–∫–∏–µ —Å–∫–æ—Ä—ã —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤')
        
        # –ê–Ω–∞–ª–∏–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        filtered_out = rerank_diagnostics.get('filtered_out', 0)
        total_results = rerank_diagnostics.get('total_results', 0)
        
        if filtered_out > 0:
            filter_ratio = filtered_out / max(total_results, 1)
            if filter_ratio > 0.8:
                recommendations.append(f'‚ö†Ô∏è  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {filtered_out}/{total_results} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–µ –ø–æ—Ä–æ–≥–∏')
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
        vector_count = len(vector_results)
        bm25_count = len(bm25_results)
        
        if vector_count == 0:
            recommendations.append('üî¥ –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏')
        
        if bm25_count == 0:
            recommendations.append('üî¥ BM25 –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é')
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–∞
        if len(query.split()) < 3:
            recommendations.append('üí° –ö–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞')
        
        return recommendations
    
    def test_problematic_query(self, query: str = "–ü—Ä–∏—à–ª–∏ –ø–æ—á—Ç—É –ê–Ω—Ç–æ–Ω–∞") -> DiagnosticResult:
        """–¢–µ—Å—Ç –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞"""
        logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{query}'")
        return self.diagnose_query(query, access_level=100)
    
    def print_diagnostic_report(self, result: DiagnosticResult):
        """–ü–µ—á–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
        print("\n" + "="*80)
        print(f"üîç –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ô –û–¢–ß–ï–¢")
        print("="*80)
        print(f"–ó–∞–ø—Ä–æ—Å: '{result.query}'")
        print(f"–£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–∞: {result.access_level}")
        print()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:")
        print(f"  –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫: {len(result.vector_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print(f"  BM25 –ø–æ–∏—Å–∫: {len(result.bm25_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print(f"  –ü–æ—Å–ª–µ fusion: {len(result.fused_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print(f"  –ü–æ—Å–ª–µ —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: {len(result.reranked_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print()
        
        # –°–∫–æ—Ä—ã —Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        if result.rerank_scores:
            print("üéØ –°–ö–û–†–´ –†–ï–†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"  –õ—É—á—à–∏–π: {max(result.rerank_scores):.3f}")
            print(f"  –•—É–¥—à–∏–π: {min(result.rerank_scores):.3f}")
            print(f"  –°—Ä–µ–¥–Ω–∏–π: {sum(result.rerank_scores)/len(result.rerank_scores):.3f}")
            print(f"  –†–∞–∑–±—Ä–æ—Å: {max(result.rerank_scores) - min(result.rerank_scores):.3f}")
            print()
        
        # –ü–æ—Ä–æ–≥–∏
        thresholds = result.thresholds
        print("üö™ –ü–û–†–û–ì–ò –§–ò–õ–¨–¢–†–ê–¶–ò–ò:")
        print(f"  –í—ã—Å–æ–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {thresholds.get('high_relevance', 0):.3f}")
        print(f"  –û–±—â–∏–π —á–∞—Ç: {thresholds.get('general_chat', 0):.3f}")
        print()
        
        # –¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("üèÜ –¢–û–ü –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        for i, result_item in enumerate(result.reranked_results[:3]):
            print(f"  #{i+1} (—Å–∫–æ—Ä: {result_item.get('rerank_score', 0):.3f})")
            content = result_item.get('content', '')[:100] + '...' if len(result_item.get('content', '')) > 100 else result_item.get('content', '')
            print(f"      {content}")
            print()
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = result.diagnostics.get('recommendations', [])
        if recommendations:
            print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in recommendations:
                print(f"  {rec}")
            print()
        
        # –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞
        quality = result.diagnostics.get('quality', {})
        issues = quality.get('issues', [])
        if issues:
            print("‚ö†Ô∏è  –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
            for issue in issues:
                print(f"  ‚Ä¢ {issue}")
            print()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    parser = argparse.ArgumentParser(description='–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--query', '-q', type=str, help='–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏')
    parser.add_argument('--access-level', '-a', type=int, default=100, help='–£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100)')
    parser.add_argument('--test-problematic', '-t', action='store_true', help='–¢–µ—Å—Ç –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞')
    parser.add_argument('--json', '-j', action='store_true', help='–í—ã–≤–æ–¥ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ')
    
    args = parser.parse_args()
    
    try:
        diagnostics = SearchDiagnostics()
        
        if args.test_problematic:
            result = diagnostics.test_problematic_query()
        elif args.query:
            result = diagnostics.diagnose_query(args.query, args.access_level)
        else:
            # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
            query = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ").strip()
            if not query:
                print("–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å. –í—ã—Ö–æ–¥.")
                return
            result = diagnostics.diagnose_query(query, args.access_level)
        
        if args.json:
            # –í—ã–≤–æ–¥ –≤ JSON (–¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
            output = {
                'query': result.query,
                'access_level': result.access_level,
                'results_count': len(result.reranked_results),
                'rerank_scores': result.rerank_scores,
                'thresholds': result.thresholds,
                'diagnostics': result.diagnostics
            }
            print(json.dumps(output, ensure_ascii=False, indent=2))
        else:
            # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
            diagnostics.print_diagnostic_report(result)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
